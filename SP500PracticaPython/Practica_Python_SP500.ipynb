{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica Python\n",
    "## Alumnos: _Tania Batista, Fernando de la Fuente, Lourdes Ruiz_\n",
    "## Tema: Análisis del S&P 500\n",
    "### Profesor: _Miguel Angel Sicilia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos elegido para la práctica una tabla de datos que contiene las cotizaciones de 503 valores que componen el índice de bolsa americana S&P 500 de 5 años, desde el 13 de Agosto de 2012 hasta el 11 de Agosto de 2017.\n",
    "Los datos están extraídos de Kaggle, en el siguiente repositorio:\n",
    "\n",
    "[Kaggle S&P 500](https://www.kaggle.com/camnugent/sandp500/)\n",
    "\n",
    "A partir de estos datos, sin tener los datos del índice, sino los de los valores que lo componen, haremos algunos estudios, así como la composición de un índice sintético.\n",
    "Deicidimos componer un sintético debido a que:\n",
    "* El índice real varía diariamente el peso de cada uno de los valores que lo componen, y el acceso a esta información que es necesaria para componer el índice real es de pago. \n",
    "* Periodicamente se reune un comité que decide qué valores entran y salen del índice, y a lo largo de los 5 años de los que tenemos datos ha habido varios valores que han entrado y otros que han salido. Nuestra base de datos contiene información de los 503 valores que componían el índice en fecha 14 de Agosto de 2017, y sobre esta información es sobre la que trabajaremos.\n",
    "\n",
    "Por tanto, debido a estas limitaciones no es posible recomponer el índice real y comprobar los datos obtenidos con los de cualquier otra fuente, y en consecuencia fabricaremos uno sintético asumiendo que en el periodo no ha variado la composición, y todos los valores tienen el mismo peso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos por tanto la práctica.\n",
    "\n",
    "Lo primero sería cargar los datos, y volcarlos a un data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PRUEBA PARA ABRIR EL FICHERO DESDE LA URL, ESTA COMPRIMIDO EN ORIGEN\n",
    "import pandas as pd\n",
    "import bz2\n",
    "path ='https://www.kaggle.com/camnugent/sandp500/downloads/all_stocks_5yr.csv.bz2'\n",
    "sp500 = pd.read_csv(path, delimiter=',',decimal='.', header=0)\n",
    "sp = pd.DataFrame(sp500)\n",
    "print(sp.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PRUEBA PARA ABRIR EL FICHERO DESDE LA CARPETA DESCARGAS, ESTA COMPRIMIDO AL DESCARGARLO. --> FUNCIONA\n",
    "import pandas as pd\n",
    "path ='C:\\\\Users\\\\ffuen\\\\Downloads\\\\all_stocks_5yr.csv.zip'\n",
    "sp500 = pd.read_csv(path, delimiter=',',decimal='.', header=0)\n",
    "print(sp500.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date   Open   High    Low  Close     Volume Name\n",
      "0  2012-08-13  92.29  92.59  91.74  92.40  2075391.0  MMM\n",
      "1  2012-08-14  92.36  92.50  92.01  92.30  1843476.0  MMM\n",
      "2  2012-08-15  92.00  92.74  91.94  92.54  1983395.0  MMM\n",
      "3  2012-08-16  92.75  93.87  92.21  93.74  3395145.0  MMM\n",
      "4  2012-08-17  93.93  94.30  93.59  94.24  3069513.0  MMM\n",
      "5  2012-08-20  94.00  94.17  93.55  93.89  1640008.0  MMM\n",
      "6  2012-08-21  93.98  94.10  92.99  93.21  2302988.0  MMM\n",
      "7  2012-08-22  92.56  93.36  92.43  92.68  2463908.0  MMM\n",
      "8  2012-08-23  92.65  92.68  91.79  91.98  1823757.0  MMM\n",
      "9  2012-08-24  92.03  92.97  91.94  92.83  1945796.0  MMM\n",
      "              Date   Open   High    Low  Close     Volume Name\n",
      "606791  2017-07-31    NaN    NaN  62.32  62.52  2130374.0  ZTS\n",
      "606792  2017-08-01  62.60  62.69  61.92  62.27  1750974.0  ZTS\n",
      "606793  2017-08-02  62.04  62.21  61.38  61.54  1831228.0  ZTS\n",
      "606794  2017-08-03  61.23  62.47  61.20  62.28  1768815.0  ZTS\n",
      "606795  2017-08-04  62.37  62.85  61.86  62.12  1277542.0  ZTS\n",
      "606796  2017-08-07  62.12  62.34  61.25  61.83  4208287.0  ZTS\n",
      "606797  2017-08-08  60.49  61.00  59.50  60.00  4663668.0  ZTS\n",
      "606798  2017-08-09  59.95  60.87  59.76  60.81  4017297.0  ZTS\n",
      "606799  2017-08-10  60.87  61.37  59.71  59.74  2690725.0  ZTS\n",
      "606800  2017-08-11  60.05  60.22  59.64  59.73  2285863.0  ZTS\n"
     ]
    }
   ],
   "source": [
    "# POR EL MOMENTO ESTA ES LA CELDA DE CARGA DE DATOS CORRECTA, DESDE LOCAL.\n",
    "# ELIMINARLA CUANDO TENGAMOS CARGA DE DATOS DESDE URL\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import csv, operator\n",
    "path ='C:\\\\Users\\\\ffuen\\\\Desktop\\\\all_stocks_5yr.csv'\n",
    "#path ='https://www.kaggle.com//camnugent//sandp500//downloads//all_stocks_5yr.csv'\n",
    "sp500 = pd.read_csv(path, delimiter=',',decimal='.', header=0, )\n",
    "sp = pd.DataFrame(sp500)\n",
    "print(sp.head(10))\n",
    "print(sp.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos la cantidad de información que tiene la tabla, en filas y columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(606801, 7)\n",
      "El número de dimensiones del data frame es de 2\n",
      "El número de filas del data frame es de 606801\n",
      "RangeIndex(start=0, stop=606801, step=1)\n",
      "El número de columnas del data frame es de 7\n",
      "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Name'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(sp.shape)\n",
    "print(\"El número de dimensiones del data frame es de\",sp.ndim)\n",
    "print(\"El número de filas del data frame es de\",len(sp.index))\n",
    "print(sp.index)\n",
    "print(\"El número de columnas del data frame es de\",len(sp.columns))\n",
    "print(sp.columns)\n",
    "print(type(sp500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto anteriormente, la tabla hacia el final tiene algunos campos vacíos, que se suplen con 'NaN'. \n",
    "\n",
    "Es necesario identificarlos, y sustituirlos para limpiar la tabla antes de trabajar con ella:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date      False\n",
      "Open       True\n",
      "High       True\n",
      "Low        True\n",
      "Close     False\n",
      "Volume     True\n",
      "Name      False\n",
      "dtype: bool\n",
      "/nEl número de campos vacíos en la columna Date es 0\n",
      "El número de campos vacíos en la columna Open es 384\n",
      "El número de campos vacíos en la columna High es 208\n",
      "El número de campos vacíos en la columna Low es 227\n",
      "El número de campos vacíos en la columna Close es 0\n",
      "El número de campos vacíos en la columna Volume es 406\n",
      "El número de campos vacíos en la columna Name es 0\n"
     ]
    }
   ],
   "source": [
    "print(sp.isnull().any())\n",
    "print(\"/nEl número de campos vacíos en la columna Date es\",sp[\"Date\"].isnull().sum())\n",
    "print(\"El número de campos vacíos en la columna Open es\",sp[\"Open\"].isnull().sum())\n",
    "print(\"El número de campos vacíos en la columna High es\",sp[\"High\"].isnull().sum())\n",
    "print(\"El número de campos vacíos en la columna Low es\",sp[\"Low\"].isnull().sum())\n",
    "print(\"El número de campos vacíos en la columna Close es\",sp[\"Close\"].isnull().sum())\n",
    "print(\"El número de campos vacíos en la columna Volume es\",sp[\"Volume\"].isnull().sum())\n",
    "print(\"El número de campos vacíos en la columna Name es\",sp[\"Name\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, los campos vacíos se encuentran en algunas columnas, no todas. \n",
    "Antes de decidir qué hacer con ellos, hagamos un análisis de qué información es la que contiene cada columna:\n",
    "* _Date:_ Contiene la fecha de la información de cada fila.\n",
    "* _Open:_ Es el primer precio al que abrió el valor ese día.\n",
    "* _High:_ El precio más alto negociado en el día.\n",
    "* _Low:_ El precio más bajo negociado en el día.\n",
    "* _Close:_ Indica a qué precio cerró el valor ese día. Este podemos decir que es el dato más importante de la fila.\n",
    "* _Volume:_ Indica el número de acciones negociadas en el día. No todas cambian de manos al mismo precio.\n",
    "* _Name:_ Indica el nombre del valor. Es una abreviatura utilizada para identificar cada valor. Por ejemplo: Amazon sería AMZN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna Name contiene 503 valores distintos.\n",
      "Son las compañías que formaban el índice S&P en fecha 11 de Agosto de 2017.\n"
     ]
    }
   ],
   "source": [
    "print(\"La columna Name contiene\",len(sp.Name.unique()),\"valores distintos.\")\n",
    "\n",
    "print(\"Son las compañías que formaban el índice S&P en fecha 11 de Agosto de 2017.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a sustituir los NaN que aparezcan en las columnas High y Low por un valor, que será:\n",
    "* Para la columna _High_ el resultado de incrementar el precio de cierre de ese día por la diferencia (en %) entre el High y el Close --> High = Close * ( 1 + (% diferencia media entre High y Close de todo el periodo)\n",
    "* Para la columna _Low_ el resultado de disminuir el precio de cierre de ese día por la diferencia (en %) entre el Low y el Close --> Low = Close * ( 1 - (% diferencia media entre el Close y el Low de todo el periodo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sustituiremos primero los datos de la columna _High_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de campos vacíos en la columna High antes de la sustitución es 208\n",
      "El número de campos vacíos en la columna High después de la sustitución es 0\n"
     ]
    }
   ],
   "source": [
    "#OBTENER PROMEDIO, POR CADA VALOR, DE LA DIFERENCIA EN % ENTRE EL CIERRE Y EL HIGH, y SUSTITUIMOS LOS NAN POR ESTE CALCULO\n",
    "\n",
    "def calculo_reemplazo_high(name):\n",
    "    subset = sp[sp['Name'] == name]\n",
    "    subset_high = subset['High']\n",
    "    subset_close = subset['Close']\n",
    "    media = np.mean( (subset_high - subset_close) / subset_close) # --> Esta es la fórmula que calcula el promedio)\n",
    "    return media\n",
    "\n",
    "# Recorremos los campos que tienen algún NaN en la columna High (son 208), y los sustituimos.\n",
    "\n",
    "print(\"El número de campos vacíos en la columna High antes de la sustitución es\",sp['High'].isnull().sum())\n",
    "\n",
    "for posiciones in sp['High'].index[sp['High'].apply(np.isnan)]:\n",
    "    sp.loc[posiciones,'High'] = sp['Close'][posiciones] * (1 + calculo_reemplazo_high(sp['Name'][posiciones]))\n",
    "    \n",
    "print(\"El número de campos vacíos en la columna High después de la sustitución es\",sp['High'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora sustituiremos los datos de _Low_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de campos vacíos en la columna Low antes de la sustitución es 227\n",
      "El número de campos vacíos en la columna Low después de la sustitución es 0\n"
     ]
    }
   ],
   "source": [
    "#OBTENER PROMEDIO, POR CADA VALOR, DE LA DIFERENCIA EN % ENTRE EL CIERRE Y EL LOW, y SUSTITUIMOS LOS NAN POR ESTE CALCULO\n",
    "\n",
    "def calculo_reemplazo_low(name):\n",
    "    subset = sp[sp['Name'] == name]\n",
    "    subset_low = subset['Low']\n",
    "    subset_close = subset['Close']\n",
    "    media = np.mean( (subset_low - subset_close) / subset_close) # --> Esta es la fórmula que calcula el promedio\n",
    "    return media\n",
    "\n",
    "# Recorremos los campos que tienen algún NaN en la columna Low (son 227), y los sustituimos.\n",
    "\n",
    "print(\"El número de campos vacíos en la columna Low antes de la sustitución es\",sp['Low'].isnull().sum())\n",
    "\n",
    "for posiciones in sp['Low'].index[sp['Low'].apply(np.isnan)]:\n",
    "    sp.loc[posiciones,'Low'] = sp['Close'][posiciones] * (1 + calculo_reemplazo_low(sp['Name'][posiciones]))\n",
    "    \n",
    "print(\"El número de campos vacíos en la columna Low después de la sustitución es\",sp['Low'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a sustituir los NaN que haya en al columna _Open_, por un número aleatorio que esté entre el valor de la columna _High_ y _Low_ de esa sesión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de campos vacíos en la columna Open antes de la sustitución es 384\n",
      "El número de campos vacíos en la columna Open después de la sustitución es 0\n"
     ]
    }
   ],
   "source": [
    "# SUSTITUCION DE NaN EN COLUMNA Open, con un aleatorio que esté en el rango entre el High y el Low\n",
    "\n",
    "print(\"El número de campos vacíos en la columna Open antes de la sustitución es\",sp['Open'].isnull().sum())\n",
    "\n",
    "for posiciones in sp['Open'].index[sp['Open'].apply(np.isnan)]: \n",
    "    sp.loc[posiciones,'Open'] = np.random.uniform (sp['Low'][posiciones], sp['High'][posiciones])\n",
    "\n",
    "print(\"El número de campos vacíos en la columna Open después de la sustitución es\",sp['Open'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respecto a la columna _Volume_, para cada valor que tenga NaN (aunque solo es un único valor) calcularemos la media del volumen de títulos que se negocian diariamente, y sustituiremos el NaN por esta media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de campos vacíos en toda la tabla en la columna Volume es 406\n",
      "Los valores que tienen algún NaN en la columna Volume son:  ['GOOG']\n",
      "El número de campos vacíos en la columna Volume es 0\n"
     ]
    }
   ],
   "source": [
    "print(\"El número de campos vacíos en toda la tabla en la columna Volume es\",sp[\"Volume\"].isnull().sum())\n",
    "\n",
    "a = sp['Volume'].index[sp['Volume'].apply(np.isnan)]\n",
    "a = np.unique(sp.loc[a[0:-1],'Name'])\n",
    "print(\"Los valores que tienen algún NaN en la columna Volume son: \",a)\n",
    "\n",
    "for valores in a:\n",
    "    sp[sp['Name']==valores] = sp[sp['Name']== valores].fillna(sp[sp['Name']== valores].mean())\n",
    "\n",
    "print(\"El número de campos vacíos en la columna Volume es\",sp[\"Volume\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hechos los reemplazos de los datos nulos en las columnas, comprobamos que no quede ninguno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date      False\n",
      "Open      False\n",
      "High      False\n",
      "Low       False\n",
      "Close     False\n",
      "Volume    False\n",
      "Name      False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(sp.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la información que tenemos ahora, datos diarios de 503 valores que componen el índice S&P 500, vamos a componer un índice nosotros, similar al original, para poder centrar parte de nuestro análisis en él.\n",
    "\n",
    "### CONSIDERACIONES PRELIMINARES SOBRE EL ÍNDICE S&P 500\n",
    "El índice S&P 500 es el índice más representativo de la evolución del mercado norteamericano, y recoge la evolución de las 500 mayores empresas cotizadas en los distintos mercados de renta variable del país. Hoy en día está formado por 503 valores, dado que algunos de ellos tienen distintas clases de acciones con diferentes derechos cotizando.\n",
    "Un comité es el encargado de la selección de valores que lo componen, siguiendo 8 criterios, que son: capitalización bursatil, liquidez, domicilio, capital flotante, clasificación del sector, viabilidad financiera, periodo de tiempo durante el cual ha cotizado en bolsa y ser negociada en la bolsa de valores.\n",
    "\n",
    "El comité se reune periódicamente y decide los valores que entran y salen del índice. Respecto a la ponderación de cada valor dentro del índice, esta depende de la capitalización de mercado de cada valor (precio diario X número de acciones en circulación). \n",
    "\n",
    "No disponemos en el dataframe del número de acciones que tiene en circulación cada compañía que forma el índice, y por tanto, **no nos es posible construir una reproducción fiel al original del índice S&P 500**. Aunque tuviésemos esta información, durante los 5 años de datos que tenemos han entrado y salido valores del índice, y no disponemos de los datos diarios de los que han salido. \n",
    "\n",
    "No obstante, podemos construir un índice sintético alterando las ponderaciones de los valores, utilizando el método *'EQUALLY WEIGHTED'*, en el que todos los valores tienen el mismo peso dentro del índice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONSTRUCCIÓN DEL ÍNDICE\n",
    "Para crear el indice necesitamos 2 cosas:\n",
    "* *Un valor inicial* --> Tomaremos como referencia el valor del S&P el 10 de Agosto de 2012, un día hábil antes de la fecha a partir de la cual tenemos datos. Ese día el S&P 500 cerró a 1.405,87 y será el valor a partir del cual partamos.\n",
    "* *Variaciones diarias del índice* --> A partir de las variaciones diarias de los 504 valores haremos que el índice se mueva diariamente.\n",
    "\n",
    "Lo primero que tenemos que hacer entonces, es crear una fila para cada día con información del índice, que estará en varias columnas:\n",
    "* *Date:* fecha en la que se recoge la información\n",
    "* *Open:* precio en el que abre el índice. Carece de sentido real, ya que los precios a los que abre cada valor no tienen por qué coincidir en el tiempo (unos pueden cruzar operaciones nada más abrir el mercado, pero otros pueden hacerlo más tarde).\n",
    "* *High:* precio más alto alcanzado por el índice. Carece también de sentido real, ya que los High de cada valor se producen en diferentes momentos durante la sesión.\n",
    "* *Low:* precio más bajo alcanzado por el índice. Carece también de sentido real, ya que los Low de cada valor se producen en diferentes momentos durante la sesión.\n",
    "* *Close:* precio al que cierra el índice. Es el dato más importante, y se construye a partir de los cierres de los 504 valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero antes de eso, debemos ordenar la tabla por valor y luego por fecha, para posteriormente añadir una columna a nuestro dataframe que recoja la variación diaria de cada valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "5         0.0\n",
       "6         0.0\n",
       "7         0.0\n",
       "8         0.0\n",
       "9         0.0\n",
       "10        0.0\n",
       "11        0.0\n",
       "12        0.0\n",
       "13        0.0\n",
       "14        0.0\n",
       "15        0.0\n",
       "16        0.0\n",
       "17        0.0\n",
       "18        0.0\n",
       "19        0.0\n",
       "20        0.0\n",
       "21        0.0\n",
       "22        0.0\n",
       "23        0.0\n",
       "24        0.0\n",
       "25        0.0\n",
       "26        0.0\n",
       "27        0.0\n",
       "28        0.0\n",
       "29        0.0\n",
       "         ... \n",
       "606771    0.0\n",
       "606772    0.0\n",
       "606773    0.0\n",
       "606774    0.0\n",
       "606775    0.0\n",
       "606776    0.0\n",
       "606777    0.0\n",
       "606778    0.0\n",
       "606779    0.0\n",
       "606780    0.0\n",
       "606781    0.0\n",
       "606782    0.0\n",
       "606783    0.0\n",
       "606784    0.0\n",
       "606785    0.0\n",
       "606786    0.0\n",
       "606787    0.0\n",
       "606788    0.0\n",
       "606789    0.0\n",
       "606790    0.0\n",
       "606791    0.0\n",
       "606792    0.0\n",
       "606793    0.0\n",
       "606794    0.0\n",
       "606795    0.0\n",
       "606796    0.0\n",
       "606797    0.0\n",
       "606798    0.0\n",
       "606799    0.0\n",
       "606800    0.0\n",
       "Name: Change, Length: 606801, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp['Change'] = np.zeros(sp.index.size)\n",
    "for valor in lista_valores:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
